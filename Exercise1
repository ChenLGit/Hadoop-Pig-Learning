-- Exercise1, read data and dump data to the screen

--run from the local mode 
daily = LOAD '/home/hadoop/Documents/exercise/NYSE_daily.txt' as (exchange:chararray, symbol:chararray,  date:chararray, open:float, high:float, low:float, close:float, 	volume:int, adj_close:float); --using PigStorage('\t');
DUMP daily; 


-- run on cluster mode 
daily = LOAD '/pig/input/NYSE_daily.txt' as (exchange:chararray, symbol:chararray,  date:chararray, open:float, high:float, low:float, close:float, 	volume:int, adj_close:float); --using PigStorage('\t');
DUMP daily; 


--STORE daily into 'pig/output' using PigStorage(',');
-- save the file to exist folder will lead to an error
-- generate the output to pig/output folder (part-* is our output)
-- hadoop fs -lsr pig/output
-- hadoop fs -tail pig/output/part-m-00000
-- hadoop fs -get pig/output/part-m-00000 /home/training/pig/output/out.csv
-- then we can get the file in our local folder /home/training/pig/output
